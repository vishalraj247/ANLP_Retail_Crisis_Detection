{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw8l_XuJL3p2"
      },
      "source": [
        "# Classification Model Trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\visha\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.5.5)\n",
            "Requirement already satisfied: requests in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\visha\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "viPkAsZETA-Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\visha/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\visha/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "from textblob import TextBlob\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime\n",
        "import time\n",
        "import dateutil.parser\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QPagOR6w-6Z3"
      },
      "source": [
        "## Articles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K05eyE4sC1tk",
        "outputId": "b0faa74a-d7d3-4237-b171-1e2c022b537a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                title  \\\n",
            "0                   Is Amazon done disrupting retail?   \n",
            "1   As consumers return to stores, why would Amazo...   \n",
            "2   Amazon continues to open suburban Go locations...   \n",
            "3   Amazon buys mechatronics firm to fold into rob...   \n",
            "4   Amazon offers sellers free software to speed f...   \n",
            "..                                                ...   \n",
            "94   Grove Collaborative expands into Walmart, Amazon   \n",
            "95  Amazon rebrands discounted membership as it la...   \n",
            "96            Amazon schedules Prime Day for mid-July   \n",
            "97  What Amazon’s product updates say about its st...   \n",
            "98           Amazon launches virtual try-on for shoes   \n",
            "\n",
            "              published_date  \\\n",
            "0     Published Dec. 5, 2022   \n",
            "1    Published July 25, 2022   \n",
            "2    Published Feb. 13, 2023   \n",
            "3   Published Sept. 14, 2022   \n",
            "4   Published Sept. 20, 2022   \n",
            "..                       ...   \n",
            "94   Published Feb. 14, 2023   \n",
            "95    Published Oct. 4, 2022   \n",
            "96   Published June 16, 2022   \n",
            "97  Published Sept. 29, 2022   \n",
            "98    Published June 9, 2022   \n",
            "\n",
            "                                              content  \\\n",
            "0   Amazon has spent the better part of a quarter ...   \n",
            "1   The pandemic supercharged e-commerce as even m...   \n",
            "2   Dive Brief:Amazon will expand its suburban Go ...   \n",
            "3   Dive Brief:Amazonsaid last weekit had agreed t...   \n",
            "4   Dive Brief:Amazonannounced Thursdayit would of...   \n",
            "..                                                ...   \n",
            "94  Expanding its wholesale channels, Grove Collab...   \n",
            "95  Dive Brief:Amazon unveiled a hub for discounts...   \n",
            "96  Dive Brief:Prime Day this yearwill commenceat ...   \n",
            "97  Amazon’s latest product announcements and upda...   \n",
            "98  Dive Brief:Following the opening of Amazon’s f...   \n",
            "\n",
            "                                                  url  crisis_annotation  \n",
            "0   https://www.retaildive.com/news/amazon-done-di...               True  \n",
            "1   https://www.retaildive.com/news/Why-amazon-shu...               True  \n",
            "2   https://www.retaildive.com/news/amazon-go-open...              False  \n",
            "3   https://www.retaildive.com/news/Amazon-buys-Cl...              False  \n",
            "4   https://www.retaildive.com/news/amazon-provide...               True  \n",
            "..                                                ...                ...  \n",
            "94  https://www.retaildive.com/news/grove-collabor...              False  \n",
            "95  https://www.retaildive.com/news/amazon-launche...               True  \n",
            "96  https://www.retaildive.com/news/amazon-prime-d...               True  \n",
            "97  https://www.retaildive.com/news/amazon-product...              False  \n",
            "98  https://www.retaildive.com/news/amazon-virtual...              False  \n",
            "\n",
            "[99 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "base_url = 'https://www.retaildive.com'\n",
        "topic_urls = [\n",
        "    \"https://www.retaildive.com/search/\"\n",
        "]\n",
        "\n",
        "def get_article_links(topic_url, page_number):\n",
        "    url = f'{topic_url}?page={page_number}&q=Amazon'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    article_links = soup.select('.feed__title a')\n",
        "    links = []\n",
        "    for link in article_links:\n",
        "        url = link['href'] if link['href'].startswith(base_url) else base_url + link['href']\n",
        "        if url not in visited_urls:\n",
        "            links.append(url)\n",
        "            visited_urls.add(url)\n",
        "    return links\n",
        "\n",
        "\n",
        "pages_to_scrape = list(range(1, 10))\n",
        "\n",
        "all_article_links = []\n",
        "visited_urls = set()\n",
        "\n",
        "for topic_url in topic_urls:\n",
        "    for page_number in pages_to_scrape:\n",
        "        article_links = get_article_links(topic_url, page_number)\n",
        "        all_article_links.extend(article_links)\n",
        "\n",
        "def parse_date(date_string):\n",
        "    try:\n",
        "        # Remove \"Published \" if it's present\n",
        "        date_string = date_string.replace(\"Published \", \"\")\n",
        "        \n",
        "        # try to parse the date string using dateutil\n",
        "        return dateutil.parser.parse(date_string)\n",
        "    except ValueError:\n",
        "        # if the date string is in an unrecognized format, return None\n",
        "        return None\n",
        "\n",
        "one_year_ago = datetime.now() - relativedelta(years=1)\n",
        "\n",
        "crisis_keywords = [\"Product recall\", \"Bankruptcy\", \"Store closure\", \"Data breach\", \"Supply chain disruption\", \"Strike\",\n",
        "                   \"Labor dispute\", \"Boycott\", \"Fraud\", \"Inventory problem\", \"Lawsuit\", \"Regulatory violation\",\n",
        "                   \"Health and safety violation\", \"Economic downturn\", \"Consumer complaint\", \"Public relations disaster\",\n",
        "                   \"Security breach\", \"Outage\", \"Shipping disruption\", \"Production halt\", \"Brand crisis\", \"Profit warning\",\n",
        "                   \"Recall\", \"Cyberattack\", \"Inflation\", \"Competition\", \"Loss of key partner\", \"Scandal\", \"Insolvency\",\n",
        "                   \"Strike action\", \"Pandemic\", \"Natural disaster\", \"Product contamination\", \"Retail crisis\", \"Retail downturn\",\n",
        "                   \"Retail bankruptcy\", \"Store closures\", \"Retail layoffs\", \"Falling sales\", \"Decreasing profits\", \"Overstock\",\n",
        "                   \"Supply chain issues\", \"High retail vacancy\", \"E-commerce competition\", \"Online shopping surge\",\n",
        "                   \"Brick-and-mortar decline\", \"Retail restructuring\", \"Retail debt\", \"Consumer behavior changes\",\n",
        "                   \"Decreased foot traffic\", \"Retail disruption\", \"Shift to digital\", \"Retail insolvency\", \"Retail liquidation\",\n",
        "                   \"Retail job cuts\", \"Retail industry collapse\", \"Retail market contraction\", \"Retail pandemic impact\",\n",
        "                   \"Changes in retail trends\", \"Retail innovation challenges\", \"Omni-channel retailing struggles\",\n",
        "                   \"Rising retail rent\", \"E-retail growth\", \"Retail technology adaptation\", \"Inventory management issues\",\n",
        "                   \"Retail real estate crisis\", \"High street crisis\", \"Retail apocalypse\", \"Decline of shopping malls\",\n",
        "                   \"Retail margin squeeze\", \"Loss of consumer confidence\", \"E-commerce crisis\", \"Online sales decline\",\n",
        "                   \"E-commerce bankruptcy\", \"E-commerce fraud\", \"Data breach\", \"Cybersecurity threats\", \"Delivery issues\",\n",
        "                   \"Supply chain disruptions\", \"Inventory management problems\", \"Consumer trust issues\", \"Decreased online traffic\",\n",
        "                   \"Online customer retention issues\", \"Digital customer service complaints\", \"Payment gateway issues\",\n",
        "                   \"E-commerce platform downtime\", \"Privacy concerns\", \"Negative online reviews\", \"E-commerce legal issues\",\n",
        "                   \"Regulatory challenges for e-commerce\", \"Technology adaptation failures\", \"E-commerce site usability issues\",\n",
        "                   \"Mobile commerce problems\", \"Social commerce challenges\", \"E-commerce return policy abuse\", \"International shipping issues\",\n",
        "                   \"E-commerce tax issues\", \"Cross-border e-commerce difficulties\", \"E-commerce SEO problems\",\n",
        "                   \"Lack of personalization in e-commerce\", \"Abandoned shopping carts\", \"E-commerce conversion rate decline\",\n",
        "                   \"E-commerce accessibility issues\", \"E-commerce localization challenges\", \"Sustainability concerns in e-commerce\",\n",
        "                   \"Product quality complaints\", \"E-commerce vendor disputes\", \"E-commerce advertising backlash\", \"Dropshipping difficulties\",\n",
        "                   \"E-commerce platform migration problems\", \"Downfall\"]\n",
        "\n",
        "articles = []\n",
        "\n",
        "for url in all_article_links:\n",
        "\n",
        "#    response = requests.get(url)\n",
        "    headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    title_element = soup.find(\"h1\", class_=\"display-heading-04\")\n",
        "    \n",
        "    # If the title element is not found, skip the iteration\n",
        "    if title_element is None or \"Amazon\" not in title_element.get_text(strip=True):\n",
        "        continue\n",
        "\n",
        "    title = title_element.get_text(strip=True)\n",
        "\n",
        "    published_date = soup.find(\"span\", class_=\"published-info\").get_text(strip=True)\n",
        "    published_date_parsed = parse_date(published_date)\n",
        "#    print(published_date_parsed)\n",
        "    article_body = soup.find(\"div\", class_=[\"add-drop-cap large medium article-body\", \"large medium article-body\"])\n",
        "\n",
        "    # If the date is None or more than one year old, skip this article\n",
        "    if published_date_parsed is None or published_date_parsed < one_year_ago:\n",
        "#        print(f\"Skipping article from {published_date_parsed}\")\n",
        "        continue\n",
        "\n",
        "    if article_body:\n",
        "        text_to_speech = article_body.find(\"div\", class_=\"text-to-speech\")\n",
        "        if text_to_speech:\n",
        "            text_to_speech.decompose()\n",
        "\n",
        "        content = article_body.get_text(strip=True)\n",
        "\n",
        "        # annotate with crisis keywords\n",
        "        crisis_annotation = False\n",
        "        for keyword in crisis_keywords:\n",
        "            if keyword.lower() in content.lower():\n",
        "                crisis_annotation = True\n",
        "                break\n",
        "\n",
        "        articles.append({\n",
        "            \"title\": title,\n",
        "            \"published_date\": published_date,\n",
        "            \"content\": content,\n",
        "            \"url\": url,\n",
        "            \"crisis_annotation\": crisis_annotation,\n",
        "        })\n",
        "    else:\n",
        "        articles.append({\n",
        "            \"title\": title,\n",
        "            \"published_date\": published_date,\n",
        "            \"content\": \"Content not found\",\n",
        "            \"url\": url,\n",
        "            \"crisis_annotation\": False,\n",
        "        })\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "df = pd.DataFrame(articles)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n0OTyh0l0iYD"
      },
      "outputs": [],
      "source": [
        "# Save as a CSV file\n",
        "df.to_csv('retaildive_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "80IiT-VYm9aj"
      },
      "outputs": [],
      "source": [
        "file_id = '1hFzsqf0YscjMCWmqrzs3Meu2PKcBSdNf'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "#df = pd.read_csv('retaildive_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBG93GlNTCxa",
        "outputId": "5c3b21dd-c5a7-4b73-bd6e-92c544dee834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   title  published_date  content  url\n",
            "crisis_annotation                                     \n",
            "False                 54              54       54   54\n",
            "True                  45              45       45   45\n"
          ]
        }
      ],
      "source": [
        "crisis_counts = df.groupby('crisis_annotation').count()\n",
        "print(crisis_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "TSHlFMk8SmJV",
        "outputId": "7e7a5209-0f11-4c5d-c41c-2f202cf6b422"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "crisis_counts.plot(kind='bar', y='title')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t0CAQyGpgsYP"
      },
      "source": [
        "### Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS6Bm4c7eTpJ",
        "outputId": "18d10a89-9e10-48e4-8f76-18ef4a83eca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "title                0\n",
            "published_date       0\n",
            "content              0\n",
            "url                  0\n",
            "crisis_annotation    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# If there are missing values in the 'content' column, remove those rows\n",
        "df = df.dropna(subset=['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-45MbvfpeWcq"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()                                                      # Convert text to lowercase\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)                                      # Remove text inside square brackets\n",
        "    punctuation = string.punctuation.replace(':', '')                        # Create a new punctuation string without ':'\n",
        "    text = re.sub(r'[%s]' % re.escape(punctuation), '', text)                # Remove punctuation marks using the new string\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)                                     # Remove words containing numbers\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)                        # Remove URLs\n",
        "    text = re.sub(r'\\W', ' ', text)                                          # Replace non-word characters with a space\n",
        "    text = re.sub('[‘’“”…]', '', text)                                       # Remove special characters\n",
        "    text = re.sub('\\n', ' ', text)                                           # Replace newline characters with a space\n",
        "    text = text.replace(':', ' ')                                            # Replace ':' with a space\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)                                # Remove non-ASCII characters\n",
        "    lemmatizer = WordNetLemmatizer()                                         # Create a WordNet lemmatizer object\n",
        "    tokens = nltk.word_tokenize(text)                                        # Tokenize the text into individual words\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]    # Lemmatize each token\n",
        "    text = ' '.join(lemmatized_tokens)                                       # Join the lemmatized tokens back into a text\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZRUxuVWey2E",
        "outputId": "4c5001e5-75a8-4d56-d884-5dc7b4b053f0"
      },
      "outputs": [],
      "source": [
        "df['processed_content'] = df['content'].apply(lambda x: clean_text(x))\n",
        "df['tokens'] = df['processed_content'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-XRgSedgQfI",
        "outputId": "219fb557-f4dc-4ea5-9c2c-4ea94299505d"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    filtered = [word for word in tokens if word not in stop_words]\n",
        "    return filtered\n",
        "\n",
        "df['tokens'] = df['tokens'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UfP-kSD1fruP"
      },
      "outputs": [],
      "source": [
        "#from nltk.stem import PorterStemmer\n",
        "\n",
        "#stemmer = PorterStemmer()\n",
        "\n",
        "#def apply_stemming(tokens):\n",
        "#    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "#df['tokens'] = df['tokens'].apply(apply_stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9T-_xikNgqjv"
      },
      "outputs": [],
      "source": [
        "df['processed_content'] = df['tokens'].apply(' '.join)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "N3lP0VzhJJFm"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_articles(article):\n",
        "    return tokenizer(article, padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "# Apply the tokenize_articles function to the 'processed_content' column of the DataFrame\n",
        "tokenized_articles = df['processed_content'].apply(tokenize_articles)\n",
        "\n",
        "# Convert the tokenized output into separate columns in the DataFrame\n",
        "df['input_ids'] = [torch.tensor(entry['input_ids']) for entry in tokenized_articles]\n",
        "df['attention_mask'] = [torch.tensor(entry['attention_mask']) for entry in tokenized_articles]\n",
        "\n",
        "# Convert crisis_annotation column to torch tensor\n",
        "df['crisis_annotation'] = df['crisis_annotation'].apply(lambda x: torch.tensor(int(x)))\n",
        "\n",
        "# Create a PyTorch Dataset from the DataFrame\n",
        "class CrisisDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.df.loc[idx, 'input_ids']\n",
        "        attention_mask = self.df.loc[idx, 'attention_mask']\n",
        "        crisis_annotation = self.df.loc[idx, 'crisis_annotation']\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': crisis_annotation}\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = CrisisDataset(train_df)\n",
        "val_dataset = CrisisDataset(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s-Evf2ALhB75",
        "outputId": "abef76c0-496f-4149-8695-143c3e4ad8e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>published_date</th>\n",
              "      <th>content</th>\n",
              "      <th>url</th>\n",
              "      <th>crisis_annotation</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>tokens</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is Amazon done disrupting retail?</td>\n",
              "      <td>Published Dec. 5, 2022</td>\n",
              "      <td>Amazon has spent the better part of a quarter ...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-done-di...</td>\n",
              "      <td>tensor(1)</td>\n",
              "      <td>amazon ha spent better part quarter century fo...</td>\n",
              "      <td>[amazon, ha, spent, better, part, quarter, cen...</td>\n",
              "      <td>[tensor(101), tensor(9733), tensor(5292), tens...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>As consumers return to stores, why would Amazo...</td>\n",
              "      <td>Published July 25, 2022</td>\n",
              "      <td>The pandemic supercharged e-commerce as even m...</td>\n",
              "      <td>https://www.retaildive.com/news/Why-amazon-shu...</td>\n",
              "      <td>tensor(1)</td>\n",
              "      <td>pandemic supercharged ecommerce even consumer ...</td>\n",
              "      <td>[pandemic, supercharged, ecommerce, even, cons...</td>\n",
              "      <td>[tensor(101), tensor(6090), tensor(3207), tens...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazon continues to open suburban Go locations...</td>\n",
              "      <td>Published Feb. 13, 2023</td>\n",
              "      <td>Dive Brief:Amazon will expand its suburban Go ...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-go-open...</td>\n",
              "      <td>tensor(0)</td>\n",
              "      <td>dive brief amazon expand suburban go cstore co...</td>\n",
              "      <td>[dive, brief, amazon, expand, suburban, go, cs...</td>\n",
              "      <td>[tensor(101), tensor(11529), tensor(4766), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Amazon buys mechatronics firm to fold into rob...</td>\n",
              "      <td>Published Sept. 14, 2022</td>\n",
              "      <td>Dive Brief:Amazonsaid last weekit had agreed t...</td>\n",
              "      <td>https://www.retaildive.com/news/Amazon-buys-Cl...</td>\n",
              "      <td>tensor(0)</td>\n",
              "      <td>dive brief amazonsaid last weekit agreed buy b...</td>\n",
              "      <td>[dive, brief, amazonsaid, last, weekit, agreed...</td>\n",
              "      <td>[tensor(101), tensor(11529), tensor(4766), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazon offers sellers free software to speed f...</td>\n",
              "      <td>Published Sept. 20, 2022</td>\n",
              "      <td>Dive Brief:Amazonannounced Thursdayit would of...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-provide...</td>\n",
              "      <td>tensor(1)</td>\n",
              "      <td>dive brief amazonannounced thursdayit would of...</td>\n",
              "      <td>[dive, brief, amazonannounced, thursdayit, wou...</td>\n",
              "      <td>[tensor(101), tensor(11529), tensor(4766), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Grove Collaborative expands into Walmart, Amazon</td>\n",
              "      <td>Published Feb. 14, 2023</td>\n",
              "      <td>Expanding its wholesale channels, Grove Collab...</td>\n",
              "      <td>https://www.retaildive.com/news/grove-collabor...</td>\n",
              "      <td>tensor(0)</td>\n",
              "      <td>expanding wholesale channel grove collaborativ...</td>\n",
              "      <td>[expanding, wholesale, channel, grove, collabo...</td>\n",
              "      <td>[tensor(101), tensor(9186), tensor(17264), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Amazon rebrands discounted membership as it la...</td>\n",
              "      <td>Published Oct. 4, 2022</td>\n",
              "      <td>Dive Brief:Amazon unveiled a hub for discounts...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-launche...</td>\n",
              "      <td>tensor(1)</td>\n",
              "      <td>dive brief amazon unveiled hub discount afford...</td>\n",
              "      <td>[dive, brief, amazon, unveiled, hub, discount,...</td>\n",
              "      <td>[tensor(101), tensor(11529), tensor(4766), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Amazon schedules Prime Day for mid-July</td>\n",
              "      <td>Published June 16, 2022</td>\n",
              "      <td>Dive Brief:Prime Day this yearwill commenceat ...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-prime-d...</td>\n",
              "      <td>tensor(1)</td>\n",
              "      <td>dive brief prime day yearwill commenceat midni...</td>\n",
              "      <td>[dive, brief, prime, day, yearwill, commenceat...</td>\n",
              "      <td>[tensor(101), tensor(11529), tensor(4766), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>What Amazon’s product updates say about its st...</td>\n",
              "      <td>Published Sept. 29, 2022</td>\n",
              "      <td>Amazon’s latest product announcements and upda...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-product...</td>\n",
              "      <td>tensor(0)</td>\n",
              "      <td>amazon latest product announcement update wedn...</td>\n",
              "      <td>[amazon, latest, product, announcement, update...</td>\n",
              "      <td>[tensor(101), tensor(9733), tensor(6745), tens...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Amazon launches virtual try-on for shoes</td>\n",
              "      <td>Published June 9, 2022</td>\n",
              "      <td>Dive Brief:Following the opening of Amazon’s f...</td>\n",
              "      <td>https://www.retaildive.com/news/amazon-virtual...</td>\n",
              "      <td>tensor(0)</td>\n",
              "      <td>dive brief following opening amazon first appa...</td>\n",
              "      <td>[dive, brief, following, opening, amazon, firs...</td>\n",
              "      <td>[tensor(101), tensor(11529), tensor(4766), ten...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                title  \\\n",
              "0                   Is Amazon done disrupting retail?   \n",
              "1   As consumers return to stores, why would Amazo...   \n",
              "2   Amazon continues to open suburban Go locations...   \n",
              "3   Amazon buys mechatronics firm to fold into rob...   \n",
              "4   Amazon offers sellers free software to speed f...   \n",
              "..                                                ...   \n",
              "94   Grove Collaborative expands into Walmart, Amazon   \n",
              "95  Amazon rebrands discounted membership as it la...   \n",
              "96            Amazon schedules Prime Day for mid-July   \n",
              "97  What Amazon’s product updates say about its st...   \n",
              "98           Amazon launches virtual try-on for shoes   \n",
              "\n",
              "              published_date  \\\n",
              "0     Published Dec. 5, 2022   \n",
              "1    Published July 25, 2022   \n",
              "2    Published Feb. 13, 2023   \n",
              "3   Published Sept. 14, 2022   \n",
              "4   Published Sept. 20, 2022   \n",
              "..                       ...   \n",
              "94   Published Feb. 14, 2023   \n",
              "95    Published Oct. 4, 2022   \n",
              "96   Published June 16, 2022   \n",
              "97  Published Sept. 29, 2022   \n",
              "98    Published June 9, 2022   \n",
              "\n",
              "                                              content  \\\n",
              "0   Amazon has spent the better part of a quarter ...   \n",
              "1   The pandemic supercharged e-commerce as even m...   \n",
              "2   Dive Brief:Amazon will expand its suburban Go ...   \n",
              "3   Dive Brief:Amazonsaid last weekit had agreed t...   \n",
              "4   Dive Brief:Amazonannounced Thursdayit would of...   \n",
              "..                                                ...   \n",
              "94  Expanding its wholesale channels, Grove Collab...   \n",
              "95  Dive Brief:Amazon unveiled a hub for discounts...   \n",
              "96  Dive Brief:Prime Day this yearwill commenceat ...   \n",
              "97  Amazon’s latest product announcements and upda...   \n",
              "98  Dive Brief:Following the opening of Amazon’s f...   \n",
              "\n",
              "                                                  url crisis_annotation  \\\n",
              "0   https://www.retaildive.com/news/amazon-done-di...         tensor(1)   \n",
              "1   https://www.retaildive.com/news/Why-amazon-shu...         tensor(1)   \n",
              "2   https://www.retaildive.com/news/amazon-go-open...         tensor(0)   \n",
              "3   https://www.retaildive.com/news/Amazon-buys-Cl...         tensor(0)   \n",
              "4   https://www.retaildive.com/news/amazon-provide...         tensor(1)   \n",
              "..                                                ...               ...   \n",
              "94  https://www.retaildive.com/news/grove-collabor...         tensor(0)   \n",
              "95  https://www.retaildive.com/news/amazon-launche...         tensor(1)   \n",
              "96  https://www.retaildive.com/news/amazon-prime-d...         tensor(1)   \n",
              "97  https://www.retaildive.com/news/amazon-product...         tensor(0)   \n",
              "98  https://www.retaildive.com/news/amazon-virtual...         tensor(0)   \n",
              "\n",
              "                                    processed_content  \\\n",
              "0   amazon ha spent better part quarter century fo...   \n",
              "1   pandemic supercharged ecommerce even consumer ...   \n",
              "2   dive brief amazon expand suburban go cstore co...   \n",
              "3   dive brief amazonsaid last weekit agreed buy b...   \n",
              "4   dive brief amazonannounced thursdayit would of...   \n",
              "..                                                ...   \n",
              "94  expanding wholesale channel grove collaborativ...   \n",
              "95  dive brief amazon unveiled hub discount afford...   \n",
              "96  dive brief prime day yearwill commenceat midni...   \n",
              "97  amazon latest product announcement update wedn...   \n",
              "98  dive brief following opening amazon first appa...   \n",
              "\n",
              "                                               tokens  \\\n",
              "0   [amazon, ha, spent, better, part, quarter, cen...   \n",
              "1   [pandemic, supercharged, ecommerce, even, cons...   \n",
              "2   [dive, brief, amazon, expand, suburban, go, cs...   \n",
              "3   [dive, brief, amazonsaid, last, weekit, agreed...   \n",
              "4   [dive, brief, amazonannounced, thursdayit, wou...   \n",
              "..                                                ...   \n",
              "94  [expanding, wholesale, channel, grove, collabo...   \n",
              "95  [dive, brief, amazon, unveiled, hub, discount,...   \n",
              "96  [dive, brief, prime, day, yearwill, commenceat...   \n",
              "97  [amazon, latest, product, announcement, update...   \n",
              "98  [dive, brief, following, opening, amazon, firs...   \n",
              "\n",
              "                                            input_ids  \\\n",
              "0   [tensor(101), tensor(9733), tensor(5292), tens...   \n",
              "1   [tensor(101), tensor(6090), tensor(3207), tens...   \n",
              "2   [tensor(101), tensor(11529), tensor(4766), ten...   \n",
              "3   [tensor(101), tensor(11529), tensor(4766), ten...   \n",
              "4   [tensor(101), tensor(11529), tensor(4766), ten...   \n",
              "..                                                ...   \n",
              "94  [tensor(101), tensor(9186), tensor(17264), ten...   \n",
              "95  [tensor(101), tensor(11529), tensor(4766), ten...   \n",
              "96  [tensor(101), tensor(11529), tensor(4766), ten...   \n",
              "97  [tensor(101), tensor(9733), tensor(6745), tens...   \n",
              "98  [tensor(101), tensor(11529), tensor(4766), ten...   \n",
              "\n",
              "                                       attention_mask  \n",
              "0   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "1   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "2   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "3   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "4   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "..                                                ...  \n",
              "94  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "95  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "96  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "97  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "98  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
              "\n",
              "[99 rows x 9 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "AGvwpvcQHDX5",
        "outputId": "606785eb-9c40-4a10-e750-c4c4c12fd034"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\visha\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (23.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\visha\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\visha\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.5.5)\n",
            "Requirement already satisfied: requests in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\visha\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\visha\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dZNDOluGmZD",
        "outputId": "4d9f3af7-7be5-4849-fce3-94249569deca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            " 67%|██████▋   | 10/15 [04:33<02:15, 27.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6774, 'learning_rate': 1.0000000000000002e-06, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [06:49<00:00, 27.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 409.0473, 'train_samples_per_second': 0.579, 'train_steps_per_second': 0.037, 'train_loss': 0.673853890101115, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=15, training_loss=0.673853890101115, metrics={'train_runtime': 409.0473, 'train_samples_per_second': 0.579, 'train_steps_per_second': 0.037, 'train_loss': 0.673853890101115, 'epoch': 3.0})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "# Define function to compute metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # function to compute metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 1/1 [00:00<00:00, 112.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6898715496063232, 'eval_accuracy': 0.45, 'eval_f1': 0.0, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 13.635, 'eval_samples_per_second': 1.467, 'eval_steps_per_second': 0.073, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print(evaluation_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.45\n",
            "F1 Score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "eval_results = evaluation_results\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Accuracy: {eval_results['eval_accuracy']}\")\n",
        "print(f\"F1 Score: {eval_results['eval_f1']}\")\n",
        "print(f\"Precision: {eval_results['eval_precision']}\")\n",
        "print(f\"Recall: {eval_results['eval_recall']}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Miscellaneous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "q_GpzsFUStmL",
        "outputId": "a4be2001-7c3d-4e7f-ddd7-be803ad44b8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-61dc3794-a535-4b98-be7f-676723a23735\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1: Date/Time</th>\n",
              "      <th>2: Tweet</th>\n",
              "      <th>3: Hashtags</th>\n",
              "      <th>14: Tweets</th>\n",
              "      <th>processed_content</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5/11/2023 4:44 AM</td>\n",
              "      <td>Fear grows with each new vanishing. People bel...</td>\n",
              "      <td>booklaunch\\nfantasy\\nIARTG\\nAmazon</td>\n",
              "      <td>8495</td>\n",
              "      <td>fear grows with each new vanishing people beli...</td>\n",
              "      <td>[fear, grows, with, each, new, vanishing, peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5/11/2023 4:44 AM</td>\n",
              "      <td>Struggling With Mental Health? Cope. What Colo...</td>\n",
              "      <td>Amazon\\nStu\\nAnxiety\\nMotivation\\nPsychology\\n...</td>\n",
              "      <td>179147</td>\n",
              "      <td>struggling with mental health cope what color ...</td>\n",
              "      <td>[struggling, with, mental, health, cope, what,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5/11/2023 4:43 AM</td>\n",
              "      <td>AI answer to the question \"Who can I sell this...</td>\n",
              "      <td>artificialintelligence\\namazon\\nmicrosoft\\nfac...</td>\n",
              "      <td>205</td>\n",
              "      <td>ai answer to the question who can i sell this ...</td>\n",
              "      <td>[ai, answer, to, the, question, who, can, i, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5/11/2023 4:42 AM</td>\n",
              "      <td>#Hermones 4 #womenshealth #Womens suffering fr...</td>\n",
              "      <td>Hermones\\nwomenshealth\\nWomens\\npcos\\npcod\\nAm...</td>\n",
              "      <td>101</td>\n",
              "      <td>hermones womenshealth womens suffering from pc...</td>\n",
              "      <td>[hermones, womenshealth, womens, suffering, fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5/11/2023 4:42 AM</td>\n",
              "      <td>Check out this #Amazon Bestseller - Windows 10...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>210532</td>\n",
              "      <td>check out this amazon bestseller windows hp sf...</td>\n",
              "      <td>[check, out, this, amazon, bestseller, windows...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>5/10/2023 7:53 AM</td>\n",
              "      <td>📓Don’t Leave Your Money Behind 📷How Expats Can...</td>\n",
              "      <td>Behind\\nMosesChavi\\nbook\\namazon\\namazonbookma...</td>\n",
              "      <td>1898</td>\n",
              "      <td>dont leave your money behind how expats can es...</td>\n",
              "      <td>[dont, leave, your, money, behind, how, expats...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>5/10/2023 7:53 AM</td>\n",
              "      <td>For a pair of shoelaces or something, I can un...</td>\n",
              "      <td>iPhone\\namazon\\ncustserv</td>\n",
              "      <td>33059</td>\n",
              "      <td>for a pair of shoelaces or something i can und...</td>\n",
              "      <td>[for, a, pair, of, shoelaces, or, something, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>5/10/2023 7:53 AM</td>\n",
              "      <td>Save 50.0% on select products from TIKTIK with...</td>\n",
              "      <td>Amazon\\nClothing\\nAccessories\\nAd\\nDeal\\nBarga...</td>\n",
              "      <td>975</td>\n",
              "      <td>save on select products from tiktik with promo...</td>\n",
              "      <td>[save, on, select, products, from, tiktik, wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>5/10/2023 7:53 AM</td>\n",
              "      <td>📓Don’t Leave Your Money Behind\\n💠How Expats Ca...</td>\n",
              "      <td>Behind\\nFinancial\\nMosesChavi\\nbook\\namazon\\na...</td>\n",
              "      <td>1898</td>\n",
              "      <td>dont leave your money behind how expats can es...</td>\n",
              "      <td>[dont, leave, your, money, behind, how, expats...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>5/10/2023 7:52 AM</td>\n",
              "      <td>RevitaLAB Hyaluron Anti-Aging Day and Night Cr...</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>344956</td>\n",
              "      <td>revitalab hyaluron antiaging day and night cre...</td>\n",
              "      <td>[revitalab, hyaluron, antiaging, day, and, nig...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61dc3794-a535-4b98-be7f-676723a23735')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61dc3794-a535-4b98-be7f-676723a23735 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61dc3794-a535-4b98-be7f-676723a23735');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           1: Date/Time                                           2: Tweet  \\\n",
              "0     5/11/2023 4:44 AM  Fear grows with each new vanishing. People bel...   \n",
              "1     5/11/2023 4:44 AM  Struggling With Mental Health? Cope. What Colo...   \n",
              "2     5/11/2023 4:43 AM  AI answer to the question \"Who can I sell this...   \n",
              "3     5/11/2023 4:42 AM  #Hermones 4 #womenshealth #Womens suffering fr...   \n",
              "4     5/11/2023 4:42 AM  Check out this #Amazon Bestseller - Windows 10...   \n",
              "...                 ...                                                ...   \n",
              "9995  5/10/2023 7:53 AM  📓Don’t Leave Your Money Behind 📷How Expats Can...   \n",
              "9996  5/10/2023 7:53 AM  For a pair of shoelaces or something, I can un...   \n",
              "9997  5/10/2023 7:53 AM  Save 50.0% on select products from TIKTIK with...   \n",
              "9998  5/10/2023 7:53 AM  📓Don’t Leave Your Money Behind\\n💠How Expats Ca...   \n",
              "9999  5/10/2023 7:52 AM  RevitaLAB Hyaluron Anti-Aging Day and Night Cr...   \n",
              "\n",
              "                                            3: Hashtags  14: Tweets  \\\n",
              "0                    booklaunch\\nfantasy\\nIARTG\\nAmazon        8495   \n",
              "1     Amazon\\nStu\\nAnxiety\\nMotivation\\nPsychology\\n...      179147   \n",
              "2     artificialintelligence\\namazon\\nmicrosoft\\nfac...         205   \n",
              "3     Hermones\\nwomenshealth\\nWomens\\npcos\\npcod\\nAm...         101   \n",
              "4                                                Amazon      210532   \n",
              "...                                                 ...         ...   \n",
              "9995  Behind\\nMosesChavi\\nbook\\namazon\\namazonbookma...        1898   \n",
              "9996                           iPhone\\namazon\\ncustserv       33059   \n",
              "9997  Amazon\\nClothing\\nAccessories\\nAd\\nDeal\\nBarga...         975   \n",
              "9998  Behind\\nFinancial\\nMosesChavi\\nbook\\namazon\\na...        1898   \n",
              "9999                                             Amazon      344956   \n",
              "\n",
              "                                      processed_content  \\\n",
              "0     fear grows with each new vanishing people beli...   \n",
              "1     struggling with mental health cope what color ...   \n",
              "2     ai answer to the question who can i sell this ...   \n",
              "3     hermones womenshealth womens suffering from pc...   \n",
              "4     check out this amazon bestseller windows hp sf...   \n",
              "...                                                 ...   \n",
              "9995  dont leave your money behind how expats can es...   \n",
              "9996  for a pair of shoelaces or something i can und...   \n",
              "9997  save on select products from tiktik with promo...   \n",
              "9998  dont leave your money behind how expats can es...   \n",
              "9999  revitalab hyaluron antiaging day and night cre...   \n",
              "\n",
              "                                                 tokens  \n",
              "0     [fear, grows, with, each, new, vanishing, peop...  \n",
              "1     [struggling, with, mental, health, cope, what,...  \n",
              "2     [ai, answer, to, the, question, who, can, i, s...  \n",
              "3     [hermones, womenshealth, womens, suffering, fr...  \n",
              "4     [check, out, this, amazon, bestseller, windows...  \n",
              "...                                                 ...  \n",
              "9995  [dont, leave, your, money, behind, how, expats...  \n",
              "9996  [for, a, pair, of, shoelaces, or, something, i...  \n",
              "9997  [save, on, select, products, from, tiktik, wit...  \n",
              "9998  [dont, leave, your, money, behind, how, expats...  \n",
              "9999  [revitalab, hyaluron, antiaging, day, and, nig...  \n",
              "\n",
              "[10000 rows x 6 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pip install keras-tuner\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare your data\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "sequences = tokenizer.texts_to_sequences(df['content'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=200)\n",
        "\n",
        "X = padded_sequences\n",
        "y = df['topic_assignment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the LSTM model within a function, as required by Keras Tuner\n",
        "def build_model(hp):\n",
        "    input_layer = Input(shape=(200,))\n",
        "    x = Embedding(input_dim=5000, output_dim=hp.Int('output_dim', min_value=32, max_value=512, step=32))(input_layer)\n",
        "    x = LSTM(hp.Int('lstm_units', min_value=32, max_value=512, step=32))(x)\n",
        "    output_layer = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(input_layer, output_layer)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                  optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='output',\n",
        "    project_name='TextGen'\n",
        ")\n",
        "\n",
        "# Perform the hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAm6JXh-1Rvl",
        "outputId": "d9201f8c-2319-47c7-f5ba-2fe9b56b4f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NOXvHZC1Wfy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare your data\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "sequences = tokenizer.texts_to_sequences(df['content'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=200)\n",
        "\n",
        "X = padded_sequences\n",
        "y = df['topic_assignment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the LSTM model within a function, as required by Keras Tuner\n",
        "def build_model(hp):\n",
        "    input_layer = Input(shape=(200,))\n",
        "    x = Embedding(input_dim=5000, output_dim=hp.Int('output_dim', min_value=32, max_value=512, step=32))(input_layer)\n",
        "    x = LSTM(hp.Int('lstm_units', min_value=32, max_value=512, step=32))(x)\n",
        "    output_layer = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(input_layer, output_layer)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                  optimizer=Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), \n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='output',\n",
        "    project_name='TextGen'\n",
        ")\n",
        "\n",
        "# Perform the hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGFn-WQy1X8q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "# Prepare the tokenizer on the texts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['content'])\n",
        "\n",
        "# Convert texts into sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(df['content'])\n",
        "\n",
        "# The unique number of words\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Prepare input sequences\n",
        "input_sequences = list()\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        in_seq = sequence[:i+1]\n",
        "        input_sequences.append(in_seq)\n",
        "\n",
        "# Pad sequences for consistent length\n",
        "max_length = max([len(seq) for seq in input_sequences])\n",
        "sequences = pad_sequences(input_sequences, maxlen=max_length, padding='pre')\n",
        "\n",
        "# Split sequences into input (X) and output (y)\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "\n",
        "# One-hot encode the output variable\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=max_length-1))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XlfyogF1edX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_text(seed_text, model, tokenizer, max_length):\n",
        "    in_text = seed_text\n",
        "    for _ in range(100):  # Generate 100 words\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length-1, padding='pre')\n",
        "        yhat = model.predict(encoded, verbose=0)\n",
        "        predicted_index = np.argmax(yhat)  # Get the index of the word with highest probability\n",
        "        out_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                out_word = word\n",
        "                break\n",
        "        in_text += ' ' + out_word\n",
        "    return in_text\n",
        "\n",
        "# Example usage:\n",
        "print(generate_text(\"This is a\", model, tokenizer, max_length))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
